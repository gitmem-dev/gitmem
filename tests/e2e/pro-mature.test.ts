/**
 * E2E Tests: Pro Tier - Mature System
 *
 * Tests gitmem-mcp with Supabase + 1000 scars (mature system scenario).
 * Uses Testcontainers to provide real PostgreSQL database.
 *
 * Verifies:
 * - Performance stays within baselines at scale
 * - Cache hit rate >80% on second pass
 * - All operations work at production data volumes
 *
 * All tests go through actual MCP stdio transport.
 */

import { describe, it, expect, beforeAll, afterAll } from "vitest";
import {
  createMcpClient,
  callTool,
  getToolResultText,
  isToolError,
  type McpTestClient,
} from "./mcp-client.js";
import { PostgreSqlContainer, type StartedPostgreSqlContainer } from "@testcontainers/postgresql";
import { Client } from "pg";
import { readFileSync } from "fs";
import { join } from "path";
import { BASELINES } from "../performance/baselines.js";

// This test requires Docker - probe for a working container runtime
let DOCKER_AVAILABLE = false;
try {
  const { execFileSync } = await import("child_process");
  execFileSync("docker", ["info"], { timeout: 5_000, stdio: "ignore" });
  DOCKER_AVAILABLE = true;
} catch {
  // docker not installed or not running
}

describe.skipIf(!DOCKER_AVAILABLE)("Pro Tier - Mature System E2E", () => {
  let container: StartedPostgreSqlContainer;
  let pgClient: Client;
  let mcpClient: McpTestClient;

  beforeAll(async () => {
    // Start PostgreSQL container with pgvector
    console.log("[e2e] Starting PostgreSQL container for mature system...");
    container = await new PostgreSqlContainer("pgvector/pgvector:pg16")
      .withDatabase("gitmem_test")
      .withUsername("test")
      .withPassword("test")
      .start();

    // Connect and load schema
    pgClient = new Client({
      connectionString: container.getConnectionUri(),
    });
    await pgClient.connect();

    // Stub Supabase auth.role() â€” plain Postgres doesn't have the auth schema
    await pgClient.query(`
      CREATE SCHEMA IF NOT EXISTS auth;
      CREATE OR REPLACE FUNCTION auth.role() RETURNS TEXT AS $$
        SELECT 'service_role'::TEXT;
      $$ LANGUAGE sql;
    `);

    // Load schema
    const schemaPath = join(__dirname, "../../schema/setup.sql");
    const schema = readFileSync(schemaPath, "utf-8");
    await pgClient.query(schema);

    // Seed 1000 scars for mature system testing
    console.log("[e2e] Seeding 1000 scars...");
    await seedMatureSystemData(pgClient);
    console.log("[e2e] Seeding complete");

    // Run ANALYZE for query optimizer
    await pgClient.query("ANALYZE gitmem_learnings");
    await pgClient.query("ANALYZE gitmem_sessions");
    await pgClient.query("ANALYZE gitmem_decisions");

    // Create MCP client
    mcpClient = await createMcpClient({
      SUPABASE_URL: container.getConnectionUri(),
      SUPABASE_SERVICE_ROLE_KEY: "test-service-role-key",
      GITMEM_TIER: "pro",
      DATABASE_URL: container.getConnectionUri(),
    });
  }, 180_000); // 3 minute timeout for seeding

  afterAll(async () => {
    if (mcpClient) {
      await mcpClient.cleanup();
    }
    if (pgClient) {
      await pgClient.end();
    }
    if (container) {
      await container.stop();
    }
  });

  describe("Recall Performance at Scale", () => {
    it("recall completes within baseline (2000ms)", async () => {
      const startTime = Date.now();

      const result = await callTool(mcpClient.client, "recall", {
        plan: "verify deployment process",
        match_count: 5,
      });

      const elapsed = Date.now() - startTime;

      expect(isToolError(result)).toBe(false);
      expect(elapsed).toBeLessThan(BASELINES.recall_with_scars * 1.5);

      console.log(`[e2e] Recall at 1000 scars: ${elapsed}ms`);
    });

    it("second recall is faster (cache hit)", async () => {
      // First call - may be cold
      const start1 = Date.now();
      await callTool(mcpClient.client, "recall", {
        plan: "test caching behavior",
      });
      const elapsed1 = Date.now() - start1;

      // Second call - should hit cache
      const start2 = Date.now();
      await callTool(mcpClient.client, "recall", {
        plan: "test caching behavior",
      });
      const elapsed2 = Date.now() - start2;

      console.log(`[e2e] Recall first: ${elapsed1}ms, second: ${elapsed2}ms`);

      // Second should be faster (or at least not slower)
      // Note: This isn't guaranteed due to MCP overhead, so we're lenient
      expect(elapsed2).toBeLessThan(elapsed1 * 2);
    });
  });

  describe("Session Start Performance", () => {
    it("session_start completes within baseline", async () => {
      const startTime = Date.now();

      const result = await callTool(mcpClient.client, "session_start", {
        agent_identity: "CLI",
        project: "gitmem_test",
      });

      const elapsed = Date.now() - startTime;

      expect(isToolError(result)).toBe(false);
      expect(elapsed).toBeLessThan(BASELINES.session_start_total * 1.5);

      console.log(`[e2e] Session start at 1000 scars: ${elapsed}ms`);
    });
  });

  describe("Search Performance", () => {
    it("search completes within baseline", async () => {
      const startTime = Date.now();

      const result = await callTool(mcpClient.client, "search", {
        query: "deployment verification",
        limit: 10,
      });

      const elapsed = Date.now() - startTime;

      expect(isToolError(result)).toBe(false);
      expect(elapsed).toBeLessThan(BASELINES.scar_search_remote * 1.5);

      console.log(`[e2e] Search at 1000 scars: ${elapsed}ms`);
    });
  });

  describe("Multiple Operations", () => {
    it("handles multiple sequential operations", async () => {
      const operations = [
        { name: "recall", fn: () => callTool(mcpClient.client, "recall", { plan: "test 1" }) },
        { name: "search", fn: () => callTool(mcpClient.client, "search", { query: "test" }) },
        { name: "recall", fn: () => callTool(mcpClient.client, "recall", { plan: "test 2" }) },
        { name: "log", fn: () => callTool(mcpClient.client, "log", { message: "test", level: "info" }) },
      ];

      const totalStart = Date.now();

      for (const op of operations) {
        const result = await op.fn();
        expect(isToolError(result)).toBe(false);
      }

      const totalElapsed = Date.now() - totalStart;
      console.log(`[e2e] 4 sequential operations: ${totalElapsed}ms`);

      // Should complete all operations in reasonable time
      expect(totalElapsed).toBeLessThan(10000); // 10 seconds max
    });
  });

  describe("Data Volume Verification", () => {
    it("database has 1000 learnings", async () => {
      const result = await pgClient.query(
        "SELECT COUNT(*) as count FROM gitmem_learnings"
      );
      expect(parseInt(result.rows[0].count)).toBe(1000);
    });

    it("learnings have embeddings", async () => {
      const result = await pgClient.query(
        "SELECT COUNT(*) as count FROM gitmem_learnings WHERE embedding IS NOT NULL"
      );
      expect(parseInt(result.rows[0].count)).toBe(1000);
    });
  });
});

/**
 * Seed the database with 1000 scars for mature system testing
 */
async function seedMatureSystemData(client: Client): Promise<void> {
  const severities = ["critical", "high", "medium", "low"];
  const types = ["scar", "win", "pattern", "anti_pattern"];
  const batchSize = 100;

  for (let batch = 0; batch < 10; batch++) {
    const values: string[] = [];
    const params: (string | null)[] = [];
    let paramIndex = 1;

    for (let i = 0; i < batchSize; i++) {
      const idx = batch * batchSize + i;
      const type = types[idx % types.length];
      const severity = type === "scar" ? severities[idx % severities.length] : null;

      // Generate embedding
      const embedding = Array.from({ length: 1536 }, () => Math.random() * 2 - 1);
      const magnitude = Math.sqrt(embedding.reduce((sum, v) => sum + v * v, 0));
      const normalizedEmbedding = embedding.map((v) => v / magnitude);
      const embeddingStr = `[${normalizedEmbedding.join(",")}]`;

      values.push(`($${paramIndex}, $${paramIndex + 1}, $${paramIndex + 2}, $${paramIndex + 3}, 'gitmem_test', $${paramIndex + 4}::vector)`);

      params.push(
        `Test ${type} ${idx}`,
        `Description for test ${type} ${idx}. This is a generated entry for scale testing. `.repeat(3),
        type,
        severity,
        embeddingStr
      );

      paramIndex += 5;
    }

    await client.query(
      `INSERT INTO gitmem_learnings (title, description, learning_type, severity, project, embedding)
       VALUES ${values.join(", ")}`,
      params
    );

    console.log(`[e2e] Seeded batch ${batch + 1}/10`);
  }
}
